{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading + Loading Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading w/ skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Tests no usable by anyone else, need to be updated\n",
    "\n",
    "from skimage.io import imread\n",
    "import glob\n",
    "import time\n",
    "\n",
    "image_paths = glob.glob('/nobackup/kp276129/test/1*/slice_010*') # 10 4k tif\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "imgs = [imread(img) for img in image_paths]\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"Time taken to read {len(image_paths)} images: {t2 - t1} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading w/ nvimagecodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAITING FOR NVIDIA TO FIX THE ISSUE https://github.com/NVIDIA/nvImageCodec/issues/5\n",
    "# from nvidia import nvimgcodec\n",
    "# import time\n",
    "# import glob\n",
    "\n",
    "# params = nvimgcodec.DecodeParams(color_spec=nvimgcodec.ColorSpec.UNCHANGED, allow_any_depth=True)\n",
    "# dec = nvimgcodec.Decoder()\n",
    "\n",
    "# t1 = time.perf_counter()\n",
    "# imgs=dec.read(glob.glob('/nobackup/kp276129/test/1*/slice_010*'), params)\n",
    "# t2 = time.perf_counter()\n",
    "# print(f\"Time taken to read images: {t2 - t1} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading into GPU (CuPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "imgs_cp = []\n",
    "\n",
    "# Converting 10 images to CuPy arrays\n",
    "t3 = time.perf_counter()\n",
    "for img in imgs:\n",
    "    imgs_cp.append(cp.asarray(img).squeeze())\n",
    "t4 = time.perf_counter()\n",
    "\n",
    "print(f\"Time taken to convert {len(imgs)} images to CuPy arrays: {t4 - t3} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing vnsr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.pyvsnr import vsnr2d\n",
    "\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "\n",
    "# Time to apply vsnr2d to 10 images one by one\n",
    "t5 = time.perf_counter()\n",
    "for img in imgs_cp:\n",
    "    vsnr2d(img, filters)\n",
    "t6 = time.perf_counter()\n",
    "\n",
    "print(f\"Time taken to apply vsnr2d to {len(imgs)} images: {t6 - t5} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "activities = ['Reading', 'Loading', 'Processing']\n",
    "\n",
    "time_taken = [t2-t1, t4-t3, t6-t5]\n",
    "\n",
    "# Create a pie chart\n",
    "plt.pie(time_taken, labels=activities, autopct='%1.1f%%', startangle=140)\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Time Distribution')\n",
    "plt.legend(activities, loc=\"best\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyvsnr VRAM Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cupy as cp\n",
    "sys.path.append('..')\n",
    "from src.pyvsnr import vsnr2d\n",
    "\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "nb_img = 1\n",
    "\n",
    "for _ in range(nb_img):\n",
    "    img = cp.random.rand(4224, 4224)\n",
    "    vsnr2d(img, filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyvsnr VRAM Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.pyvsnr import vsnr2d\n",
    "import cupy as cp\n",
    "\n",
    "%mprun -f vsnr2d vsnr2d(cp.random.rand(4224, 4224), [{'name':'Dirac', 'noise_level':0.35}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VRAM Usage for Batch Processing FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def image_generator(nb_img, batch_size):\n",
    "    for i in range(0, nb_img, batch_size):\n",
    "        batch_imgs = cp.random.rand(batch_size, 4224, 4224, dtype=cp.float32)\n",
    "        yield batch_imgs\n",
    "\n",
    "batch_size = 2\n",
    "nb_img = 100\n",
    "\n",
    "# Processing simple FFT\n",
    "for batch in image_generator(nb_img, batch_size):\n",
    "    imgs_corr = cp.fft.fft2(batch)\n",
    "\n",
    "batch_sizes = [1,2,10,20,50]\n",
    "vram_usage = [1215,1963,7947,15437,37899]\n",
    "\n",
    "# Calculate VRAM usage per image\n",
    "for i in range(1, len(batch_sizes)):\n",
    "    vram_per_image = (vram_usage[i] - vram_usage[i-1]) / (batch_sizes[i] - batch_sizes[i-1])\n",
    "    print(f\"VRAM usage per image for batch size {batch_sizes[i]} is: {vram_per_image}\")\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('VRAM Usage (MB)')\n",
    "plt.plot(batch_sizes, vram_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyvsnr Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pstats\n",
    "import cProfile\n",
    "import io\n",
    "\n",
    "sys.path.append('../')\n",
    "import src.pyvsnr as pyvsnr\n",
    "import cupy as cp\n",
    "\n",
    "img = cp.random.rand(4200, 4200)\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "pyvsnr.vsnr2d(img, filters)\n",
    "\n",
    "pr.disable()\n",
    "s = io.StringIO()\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats('time')\n",
    "ps.print_stats()\n",
    "\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch vs Individual Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pyvsnr Average Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.pyvsnr import vsnr2d\n",
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "img = cp.random.rand(2048, 2048).astype(cp.float32)\n",
    "nit=200\n",
    "\n",
    "# Calculatin average time for 100 images\n",
    "t1 = time.perf_counter()\n",
    "for i in range(nit):\n",
    "    vsnr2d(img, filters)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "# print average\n",
    "print(f\"Average time to apply vsnr2d: {(t2-t1)/nit} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pyvsnr Batch Average Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pyvsnr.vsnr2d import vsnr2d\n",
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "def batch_generator(images, batch_size):\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        yield images[i:i+batch_size]\n",
    "\n",
    "\n",
    "nb_img = 200\n",
    "batch_size = 10\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "imgs = cp.random.rand(nb_img, 2048, 2048).astype(cp.float32)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "for batch in batch_generator(imgs, batch_size):\n",
    "    vsnr2d(batch, filters, algo='cupy')\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"Average time to apply vsnr2d_batch: {(t2-t1)/nb_img} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing different batch sizes for Pyvsnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from pyvsnr.vsnr2d import vsnr2d\n",
    "import matplotlib.pyplot as plt   \n",
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "def batch_generator(images, batch_size):\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        yield cp.stack(images[i:i+batch_size])\n",
    "\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "img = cp.random.rand(2048, 2048).astype(cp.float32)\n",
    "\n",
    "batch_sizes = [5,10,15,20,25]\n",
    "times = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    t1 = time.perf_counter()\n",
    "    for batch in batch_generator([img]*200, batch_size):\n",
    "        vsnr2d(batch, filters)\n",
    "    t2 = time.perf_counter()\n",
    "    times.append((t2-t1)/200)\n",
    "\n",
    "    cp.fft.config.get_plan_cache().clear()\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.plot(batch_sizes, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multrithreading on pyvsnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually slower than processing in batch\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "sys.path.append('..')\n",
    "from src.pyvsnr import vsnr2d\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "img = np.random.rand(2048, 2048) # CuPy usage leads to CUDA initialization error\n",
    "nit=200\n",
    "\n",
    "def task(i):\n",
    "    vsnr2d(img, filters,algo=\"cuda\")\n",
    "\n",
    "# Calculating average time for 100 images\n",
    "t1 = time.perf_counter()\n",
    "with Pool(10) as pool:\n",
    "    pool.map(task, range(nit))\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "# print average\n",
    "print(f\"Average time to apply vsnr2d: {(t2-t1)/nit} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imread vs imread_collection : Same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread, imread_collection\n",
    "import glob\n",
    "import time\n",
    "\n",
    "image_paths = glob.glob('/nobackup/kp276129/test/1*/*')\n",
    "\n",
    "# Method 1 : Read with imread_collection\n",
    "t1 = time.perf_counter()\n",
    "imgs1 = list(imread_collection(image_paths))\n",
    "t2 = time.perf_counter()\n",
    "print(f\"Time taken to read images with imread_collection: {t2 - t1} seconds\")\n",
    "\n",
    "# Method 2 : Read with imread\n",
    "t3 = time.perf_counter()\n",
    "imgs2 = [imread(path) for path in image_paths]\n",
    "t4 = time.perf_counter()\n",
    "print(f\"Time taken to read images with imread: {t4 - t3} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use streams to overlap data transfer and computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from pyvsnr.vsnr2d import vsnr2d\n",
    "from tifffile import imread\n",
    "import glob\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "# List of image paths\n",
    "image_paths = glob.glob('/nobackup/kp276129/test/1*/*')\n",
    "\n",
    "# Number of images and batch size\n",
    "num_img = 100\n",
    "batch_size = 10\n",
    "\n",
    "def process_image(image):\n",
    "    return vsnr2d(image, [{'name':'Dirac', 'noise_level':0.35}])\n",
    "\n",
    "# Function to load a batch of images\n",
    "def load_batch(paths):\n",
    "    return [cp.array(imread(path)) for path in paths]\n",
    "\n",
    "# Function to process a batch of images\n",
    "def process_batch(batch):\n",
    "    return [process_image(image) for image in batch]\n",
    "\n",
    "# Create a ThreadPoolExecutor with more workers for better concurrency\n",
    "executor = ThreadPoolExecutor(max_workers=4)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "# Initialize the first batch loading\n",
    "futures = {executor.submit(load_batch, image_paths[i:i+batch_size]): i for i in range(0, num_img, batch_size)}\n",
    "results = []\n",
    "\n",
    "for future in as_completed(futures):\n",
    "    i = futures[future]\n",
    "    batch = future.result()\n",
    "    t_start = time.perf_counter()\n",
    "    result = process_batch(batch)\n",
    "    t_end = time.perf_counter()\n",
    "    results.append(result)\n",
    "    # print(f\"Processed batch {i//batch_size + 1}, processing time: {t_end - t_start:.4f} seconds\")\n",
    "    \n",
    "    # Submit the next batch\n",
    "    if i + batch_size < num_img:\n",
    "        futures[executor.submit(load_batch, image_paths[i+batch_size:i+2*batch_size])] = i + batch_size\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "print(f\"Time taken with threads: {t2 - t1} seconds\")\n",
    "\n",
    "t3 = time.perf_counter()\n",
    "\n",
    "# Process images sequentially without threads for comparison\n",
    "for i in range(0, num_img, batch_size):\n",
    "    batch = load_batch(image_paths[i:i+batch_size])\n",
    "    t_start = time.perf_counter()\n",
    "    result = process_batch(batch)\n",
    "    t_end = time.perf_counter()\n",
    "    # print(f\"Processed batch {i//batch_size + 1}, processing time: {t_end - t_start:.4f} seconds\")\n",
    "    assert cp.allclose(results[i//batch_size], result)\n",
    "\n",
    "t4 = time.perf_counter()\n",
    "print(f\"Time taken without threads: {t4 - t3} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
