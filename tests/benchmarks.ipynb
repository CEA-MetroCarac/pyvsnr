{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading + Loading + Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading w/ skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import glob\n",
    "import time\n",
    "\n",
    "image_paths = glob.glob('/nobackup/kp276129/test/1*/slice_010*') # 10 4k tif\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "imgs = [imread(img) for img in image_paths]\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"Time taken to read {len(image_paths)} images: {t2 - t1} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading w/ nvimagecodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAITING FOR NVIDIA TO FIX THE ISSUE https://github.com/NVIDIA/nvImageCodec/issues/5\n",
    "# from nvidia import nvimgcodec\n",
    "# import time\n",
    "# import glob\n",
    "\n",
    "# params = nvimgcodec.DecodeParams(color_spec=nvimgcodec.ColorSpec.UNCHANGED, allow_any_depth=True)\n",
    "# dec = nvimgcodec.Decoder()\n",
    "\n",
    "# t1 = time.perf_counter()\n",
    "# imgs=dec.read(glob.glob('/nobackup/kp276129/test/1*/slice_010*'), params)\n",
    "# t2 = time.perf_counter()\n",
    "# print(f\"Time taken to read images: {t2 - t1} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading into GPU (CuPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "imgs_cp = []\n",
    "\n",
    "# Converting 10 images to CuPy arrays\n",
    "t3 = time.perf_counter()\n",
    "for img in imgs:\n",
    "    imgs_cp.append(cp.asarray(img).squeeze())\n",
    "t4 = time.perf_counter()\n",
    "\n",
    "print(f\"Time taken to convert {len(imgs)} images to CuPy arrays: {t4 - t3} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing vnsr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.pyvsnr import vsnr2d\n",
    "\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "\n",
    "# Time to apply vsnr2d to 10 images one by one\n",
    "t5 = time.perf_counter()\n",
    "for img in imgs_cp:\n",
    "    vsnr2d(img, filters)\n",
    "t6 = time.perf_counter()\n",
    "\n",
    "print(f\"Time taken to apply vsnr2d to {len(imgs)} images: {t6 - t5} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "activities = ['Reading', 'Loading', 'Processing']\n",
    "\n",
    "time_taken = [t2-t1, t4-t3, t6-t5]\n",
    "\n",
    "# Create a pie chart\n",
    "plt.pie(time_taken, labels=activities, autopct='%1.1f%%', startangle=140)\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Time Distribution')\n",
    "plt.legend(activities, loc=\"best\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VRAM Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VRAM Usage for Batch Processing FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt \n",
    "import pynvml\n",
    "import os\n",
    "\n",
    "def image_generator(nb_img, batch_size):\n",
    "    for i in range(0, nb_img, batch_size):\n",
    "        batch_imgs = cp.random.rand(batch_size, 4224, 4224, dtype=cp.float32)\n",
    "        yield batch_imgs\n",
    "\n",
    "def get_vram_usage():\n",
    "    pynvml.nvmlInit()\n",
    "    pid = os.getpid()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    info = pynvml.nvmlDeviceGetComputeRunningProcesses(handle)\n",
    "    for p in info:\n",
    "        if p.pid == pid:\n",
    "            return p.usedGpuMemory / 1024**2\n",
    "    pynvml.nvmlShutdown()\n",
    "\n",
    "nb_img = 50\n",
    "batch_sizes = [5,10]\n",
    "vram_usage = []\n",
    "\n",
    "# Processing simple FFT\n",
    "for batch_size in batch_sizes:\n",
    "    for batch_imgs in image_generator(nb_img, batch_size):\n",
    "        filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "        cp.fft.fft2(batch_imgs)\n",
    "    vram_usage.append(get_vram_usage())\n",
    "\n",
    "# Calculate VRAM usage per image\n",
    "for i in range(1, len(batch_sizes)):\n",
    "    vram_per_image = (vram_usage[i] - vram_usage[i-1]) / (batch_sizes[i] - batch_sizes[i-1])\n",
    "    print(f\"VRAM usage per image for batch size {batch_sizes[i]} is: {vram_per_image}\")\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('VRAM Usage (MB)')\n",
    "plt.plot(batch_sizes, vram_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VRAM Usage Sequential vs Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pyvsnr.vsnr2d import vsnr2d\n",
    "import cupy as cp\n",
    "import os\n",
    "import pynvml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_vram_usage():\n",
    "    pynvml.nvmlInit()\n",
    "\n",
    "    pid = os.getpid()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    info = pynvml.nvmlDeviceGetComputeRunningProcesses(handle)\n",
    "\n",
    "    for p in info:\n",
    "        if p.pid == pid:\n",
    "            return p.usedGpuMemory / 1024**3\n",
    "    \n",
    "    pynvml.nvmlShutdown()\n",
    "\n",
    "def batch_generator(img, num_img, batch_size):\n",
    "    for i in range(0, num_img, batch_size):\n",
    "        batch = cp.stack([img]*batch_size)\n",
    "        yield batch\n",
    "\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "img = cp.random.rand(2048, 2048).astype(cp.float32)\n",
    "num_img = 60\n",
    "batch_sizes = [5,10,20]\n",
    "\n",
    "\n",
    "init_vram = get_vram_usage()\n",
    "for _ in range(num_img):\n",
    "    vsnr2d(img, filters, algo='cuda')\n",
    "single_img_vram = get_vram_usage()\n",
    "\n",
    "batch_vram = []\n",
    "for batch_size in batch_sizes:\n",
    "    for batch in batch_generator(img, num_img, batch_size):\n",
    "        vsnr2d(batch, filters, algo=\"cupy\")\n",
    "    batch_vram.append(get_vram_usage())\n",
    "    \n",
    "# Plot VRAM usage data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(batch_sizes, batch_vram, 'o-', label='Batch Processing')\n",
    "plt.axhline(y=single_img_vram, color='b', linestyle='--', label='Single Image')\n",
    "plt.axhline(y=init_vram, color='r', linestyle='--', label='Initial VRAM')\n",
    "plt.xticks(batch_sizes)  # Set the x-ticks to be the batch sizes\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('VRAM Usage (GB)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pyvsnr Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pstats\n",
    "import cProfile\n",
    "import io\n",
    "\n",
    "sys.path.append('../')\n",
    "import src.pyvsnr as pyvsnr\n",
    "import cupy as cp\n",
    "\n",
    "img = cp.random.rand(2048, 2048)\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "pyvsnr.vsnr2d(img, filters, algo='numpy')\n",
    "\n",
    "pr.disable()\n",
    "s = io.StringIO()\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats('time')\n",
    "ps.print_stats()\n",
    "\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pyvsnr Average Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.pyvsnr import vsnr2d\n",
    "# import cupy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "img = np.random.rand(2048, 2048).astype(np.float32)\n",
    "nit=100\n",
    "\n",
    "\n",
    "vsnr2d(img, filters, algo='cupy') # warm up for GPU Only\n",
    "\n",
    "# Generate different images for each iteration\n",
    "imgs = [np.random.rand(2048, 2048).astype(np.float32) for _ in range(nit)]\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "for img in imgs:\n",
    "    vsnr2d(img, filters, algo='cupy')\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "# print average\n",
    "print(f\"Average time to apply vsnr2d: {(t2-t1)/nit} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pyvsnr Batch Average Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pyvsnr.vsnr2d import vsnr2d\n",
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "def batch_generator(images, batch_size):\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        yield images[i:i+batch_size]\n",
    "\n",
    "\n",
    "nb_img = 200\n",
    "batch_size = 10\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "imgs = cp.random.rand(nb_img, 2048, 2048).astype(cp.float32)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "for batch in batch_generator(imgs, batch_size):\n",
    "    vsnr2d(batch, filters, algo='cupy')\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"Average time to apply vsnr2d_batch: {(t2-t1)/nb_img} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Sequential vs Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pyvsnr.vsnr2d import vsnr2d\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def batch_generator(img, num_img, batch_size):\n",
    "    for i in range(0, num_img, batch_size):\n",
    "        batch = np.stack([img]*batch_size)\n",
    "        yield batch\n",
    "\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "img = np.random.rand(2048, 2048).astype(cp.float32)\n",
    "num_img = 200\n",
    "batch_sizes = [5,10,20]\n",
    "\n",
    "# measure average time on 60 images\n",
    "single_processing_time = 0\n",
    "for _ in range(num_img):\n",
    "    t1 = time.perf_counter()\n",
    "    vsnr2d(img, filters, algo='cupy')\n",
    "    t2 = time.perf_counter()\n",
    "    single_processing_time += t2 - t1\n",
    "\n",
    "\n",
    "batch_times = []\n",
    "for batch_size in batch_sizes:\n",
    "    t1 = time.perf_counter()\n",
    "    for batch in batch_generator(img, num_img, batch_size):\n",
    "        vsnr2d(batch, filters, algo='cupy')\n",
    "    t2 = time.perf_counter()\n",
    "    print(f\"Time taken to process {num_img} images with batch size {batch_size}: {t2 - t1} seconds\")\n",
    "    batch_times.append(t2 - t1)  # Add the time taken for the current operation\n",
    "\n",
    "# Plot time data\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.axhline(y=single_processing_time, color='r', linestyle='--', label='Single Processing')\n",
    "ax.plot(batch_sizes, batch_times, 'o', label='Batch Processing')\n",
    "ax.set_xlabel('Batch Size')\n",
    "ax.set_ylabel('Time (s)')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multrithreading on pyvsnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually slower than processing in batch\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "sys.path.append('..')\n",
    "from src.pyvsnr import vsnr2d\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "filters=[{'name':'Dirac', 'noise_level':0.35}]\n",
    "img = np.random.rand(2048, 2048) # CuPy usage leads to CUDA initialization error\n",
    "nit=2\n",
    "\n",
    "def task(i):\n",
    "    vsnr2d(img, filters, algo=\"numpy\")\n",
    "\n",
    "# Calculating average time for 100 images\n",
    "t1 = time.perf_counter()\n",
    "with Pool(10) as pool:\n",
    "    pool.map(task, range(nit))\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "# print average\n",
    "print(f\"Average time to apply vsnr2d: {(t2-t1)/nit} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cupy Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlap data transfer and computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from pyvsnr.vsnr2d import vsnr2d\n",
    "from tifffile import imread\n",
    "import glob\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "# List of image paths\n",
    "image_paths = glob.glob('/nobackup/kp276129/test/1*/*')\n",
    "\n",
    "# Number of images and batch size\n",
    "num_img = 100\n",
    "batch_size = 10\n",
    "\n",
    "def process_image(image):\n",
    "    return vsnr2d(image, [{'name':'Dirac', 'noise_level':0.35}])\n",
    "\n",
    "# Function to load a batch of images\n",
    "def load_batch(paths):\n",
    "    return [cp.array(imread(path)) for path in paths]\n",
    "\n",
    "# Function to process a batch of images\n",
    "def process_batch(batch):\n",
    "    return [process_image(image) for image in batch]\n",
    "\n",
    "# Create a ThreadPoolExecutor with more workers for better concurrency\n",
    "executor = ThreadPoolExecutor(max_workers=4)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "# Initialize the first batch loading\n",
    "futures = {executor.submit(load_batch, image_paths[i:i+batch_size]): i for i in range(0, num_img, batch_size)}\n",
    "results = []\n",
    "\n",
    "for future in as_completed(futures):\n",
    "    i = futures[future]\n",
    "    batch = future.result()\n",
    "    t_start = time.perf_counter()\n",
    "    result = process_batch(batch)\n",
    "    t_end = time.perf_counter()\n",
    "    results.append(result)\n",
    "    # print(f\"Processed batch {i//batch_size + 1}, processing time: {t_end - t_start:.4f} seconds\")\n",
    "    \n",
    "    # Submit the next batch\n",
    "    if i + batch_size < num_img:\n",
    "        futures[executor.submit(load_batch, image_paths[i+batch_size:i+2*batch_size])] = i + batch_size\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "print(f\"Time taken with threads: {t2 - t1} seconds\")\n",
    "\n",
    "t3 = time.perf_counter()\n",
    "\n",
    "# Process images sequentially without threads for comparison\n",
    "for i in range(0, num_img, batch_size):\n",
    "    batch = load_batch(image_paths[i:i+batch_size])\n",
    "    t_start = time.perf_counter()\n",
    "    result = process_batch(batch)\n",
    "    t_end = time.perf_counter()\n",
    "    # print(f\"Processed batch {i//batch_size + 1}, processing time: {t_end - t_start:.4f} seconds\")\n",
    "    assert cp.allclose(results[i//batch_size], result)\n",
    "\n",
    "t4 = time.perf_counter()\n",
    "print(f\"Time taken without threads: {t4 - t3} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time using streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pyvsnr.vsnr2d import vsnr2d\n",
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "def calcul(arr, stream=None):\n",
    "    if stream is None:\n",
    "        stream = cp.cuda.Stream.null\n",
    "    with stream:\n",
    "        img_corr = vsnr2d(arr, [{'name':'Dirac', 'noise_level':0.35}])\n",
    "        # img_corr = cp.fft.fft2(arr)\n",
    "        # img_corr = cp.fft.ifft2(img_corr)\n",
    "    return img_corr\n",
    "\n",
    "\n",
    "img = cp.random.rand(2048, 2048).astype(cp.float32)\n",
    "imgs = cp.stack([img]*10)\n",
    "\n",
    "# Création de 10 streams CUDA\n",
    "streams = [cp.cuda.Stream(non_blocking=True) for _ in range(10)]\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "# Lancement des calculs en parallèle sur différents streams\n",
    "for i in range(10):\n",
    "    calcul(imgs[i], stream=streams[i])\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "# Synchronisation des streams pour s'assurer que tous les calculs sont terminés\n",
    "for stream in streams:\n",
    "    stream.synchronize()\n",
    "t3 = time.perf_counter()\n",
    "\n",
    "print(f\"Submit tasks: {t2 - t1} seconds\")\n",
    "print(f\"vsnr2d to 10 images in parallel: {t3 - t1} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time for sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pyvsnr.vsnr2d import vsnr2d\n",
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "def simple_calcul_sequential(arr):\n",
    "    img_corr = vsnr2d(arr, [{'name':'Dirac', 'noise_level':0.35}], algo='cupy')\n",
    "    return img_corr\n",
    "\n",
    "img = cp.random.rand(2048, 2048).astype(cp.float32)\n",
    "imgs = cp.stack([img]*10)\n",
    "\n",
    "# Lancement des calculs en séquentiel\n",
    "t1 = time.perf_counter()\n",
    "for i in range(10):\n",
    "    simple_calcul_sequential(imgs[i])\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"vsnr2d to 10 images in sequential: {t2 - t1} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streams on smaller processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "rand = cp.random.RandomState(seed=1)\n",
    "\n",
    "y = cp.random.normal(size=(2**24, 1)) # Create one random matrix in CPU\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "for _ in range(10): # Iterate over streams and execute operations asynchronously\n",
    "    x = rand.normal(size=(1, 2**24)) # Create other random matrix on GPU\n",
    "    z = cp.matmul(x, y) # Multiply matrices\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"Time to execute operations without streams: {t2 - t1} seconds\")\n",
    "\n",
    "streams = []\n",
    "for i in range(10):\n",
    "    streams.append(cp.cuda.Stream(non_blocking=True)) # Create the streams\n",
    "\n",
    "y = cp.random.normal(size=(2**24, 1)) # Create one random matrix in CPU\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "for stream in streams: # Iterate over streams and execute operations asynchronously\n",
    "    with stream:\n",
    "        x = rand.normal(size=(1, 2**24)) # Create other random matrix on GPU\n",
    "        z = cp.matmul(x, y) # Multiply matrices\n",
    "\n",
    "for stream in streams:\n",
    "    stream.synchronize() \n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"Time to execute operations asynchronously: {t2 - t1} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "\n",
    "def some_gpu_operation(x):\n",
    "    # Replace this with your actual GPU operation\n",
    "    return cp.sin(x)\n",
    "\n",
    "def test_stream_vs_sequential():\n",
    "    # Create some data\n",
    "    x = cp.random.rand(1000000)\n",
    "\n",
    "    # Sequential execution\n",
    "    start = time.time()\n",
    "    for _ in range(10):\n",
    "        y = some_gpu_operation(x)\n",
    "    sequential_time = time.time() - start\n",
    "\n",
    "    # Execution with stream\n",
    "    start = time.time()\n",
    "    stream = cp.cuda.Stream.null\n",
    "    with stream:\n",
    "        for _ in range(10):\n",
    "            y = some_gpu_operation(x)\n",
    "    stream_time = time.time() - start\n",
    "\n",
    "    # print absolute difference between times in pourcentage\n",
    "    print(f\"Stream time={stream_time}, sequential={sequential_time}\")\n",
    "    pourcentage = int((sequential_time-stream_time)/sequential_time*100)  \n",
    "    if pourcentage > 0:\n",
    "        print(f\"Stream execution was {pourcentage}% faster\")\n",
    "    else:\n",
    "        print(f\"Stream execution was {abs(pourcentage)}% slower\")\n",
    "\n",
    "    # Check that stream execution was faster\n",
    "    assert stream_time < sequential_time, f\"Stream time={stream_time}, but sequential={sequential_time}\"\n",
    "\n",
    "test_stream_vs_sequential()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
